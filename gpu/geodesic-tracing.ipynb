{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "italian-chamber",
   "metadata": {},
   "source": [
    "# GPU Accelerated Geodesic Tracing\n",
    "The work here is the research into first learning the [CUDA.jl](https://juliagpu.gitlab.io/CUDA.jl/) library and applying it to my Black Hole rendering project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "monthly-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Activating\u001b[22m\u001b[39m environment at `~/Developer/julia-resources/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "\n",
    "using CUDA, BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-turkish",
   "metadata": {},
   "source": [
    "## CPU Function\n",
    "Here is a modified version of the function I am aiming to run on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sitting-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "renderdisk (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function truncator(px) \n",
    "    floor(min(max(0, px), 255))\n",
    "end\n",
    "\n",
    "function renderdisk(\n",
    "    α::Float64,\n",
    "    β::Float64,\n",
    "    geodesics,\n",
    "    ;\n",
    "    height::Int=720,\n",
    "    width::Int=1080,\n",
    "    fov_index::Int=200,\n",
    "    rinit::Function=zeros\n",
    "    )\n",
    "\n",
    "    data = rinit(Float64, (height, width, 3))\n",
    "\n",
    "    mid = width ÷ 2 # integer division\n",
    "    mid2 = height ÷ 2 # integer division\n",
    "    n = length(geodesics)\n",
    "\n",
    "    for x in (-mid):(mid - 1)\n",
    "        \n",
    "        col = rinit(Float64, (height, 3))\n",
    "        \n",
    "        for y in 1:height-1\n",
    "            β2 = atan(y-mid2, x) # atan2\n",
    "            r = sqrt(x^2 + (y-mid2)^2) # distance from middle of image\n",
    "            i = convert(\n",
    "                Int,\n",
    "                floor(1 + r / fov_index * n)\n",
    "            )\n",
    "            if i < n\n",
    "                col[height-y, :] .= intersection(geodesics[i], α, β + β2)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        data[:, x + mid + 1, :] .= truncator.(col)\n",
    "    end\n",
    "\n",
    "    sum(data)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-express",
   "metadata": {},
   "source": [
    "For now, I'm going to simplify the intersection problem to just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intersection (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function intersection(g, α, β)\n",
    "    return 100 * β * α\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-virginia",
   "metadata": {},
   "source": [
    "Now we can get a starting benchmark for execution by generating some sample arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "center-celtic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodesics = map(\n",
    "    _ -> ones(Float64, (3, 300)),\n",
    "    1:1000\n",
    ")\n",
    "geodesics[1][:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-record",
   "metadata": {},
   "source": [
    "for which the above function takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vocational-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  21.034 ms (2162 allocations: 35.68 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "837741.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime renderdisk(π/100, 0.0, $geodesics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-suffering",
   "metadata": {},
   "source": [
    "## Naive GPU\n",
    "CUDA.jl implements an `AbstractArray` type `CuArray`, which is the basis for interchanging memory with the GPU and the host machine.\n",
    "\n",
    "The place to then start is by uploading all of the `Array` types into `CuArrays`, and then change the return init function `rinit` passed to `renderdisk` to be `CUDA.zeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "large-partnership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{CuArray{Float64,2},1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function upload(a::AbstractArray{<:Array})\n",
    "    # upload\n",
    "    [CUDA.CuArray(i) for i in a]\n",
    "end\n",
    "\n",
    "gpugeo = upload(geodesics)\n",
    "typeof(gpugeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-roots",
   "metadata": {},
   "source": [
    "Thus we get the naive benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  252.273 ms (2304171 allocations: 82.04 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "837741.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function renderdiskgpu(α, β, gpugeo)\n",
    "    renderdisk(α, β, gpugeo; rinit=CUDA.zeros)\n",
    "end\n",
    "\n",
    "@btime renderdiskgpu(π/100, 0.0, $gpugeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-prophet",
   "metadata": {},
   "source": [
    "which is significantly slower. This is to be expected, we are taking zero advantage of the GPU's hardware, and instead just running sloppy single threaded CPU code on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-traveler",
   "metadata": {},
   "source": [
    "## Using broadcasts\n",
    "The GPU is very adapted to doing *embarassingly parallel* problems, in which very little scalar multiplication happens. The first thing we ought to do is assess where our GPU code is, and what computations we are exercising.\n",
    "\n",
    "In the `renderdisk` function, we loop over `x` and `y` indices of a large zero array, representing the output image.\n",
    "\n",
    "Each loop is independent, so lets try and isolate this stage and speed it up. To make the computation costly, we'll compute the quantities `β2` and `r`.\n",
    "\n",
    "The approach when writing this is to remember\n",
    "- each loop iteration is slow, but we can do very many simultaneously\n",
    "- write to maximize number of unnested loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brutal-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  63.178 ms (4 allocations: 35.60 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10166.387038500514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function imager(rinit::Function; height=720, width=1080)\n",
    "    data = rinit(Float64, (height, width, 3))\n",
    "    \n",
    "    h_mid = height ÷ 2\n",
    "    w_mid = width ÷ 2\n",
    "        \n",
    "    values = map(\n",
    "        (i) -> begin \n",
    "            # find position\n",
    "            z = (i-1) ÷ (width * height)\n",
    "            y = (i-1 - z*width*height) ÷ width\n",
    "            x = i - ( z*width*height + y * width ) - w_mid\n",
    "            y += 1\n",
    "            z += 1\n",
    "            \n",
    "            β2 = atan(y - h_mid, x) # atan2\n",
    "            r = sqrt(x^2 + (y - h_mid)^2)\n",
    "            \n",
    "            β2\n",
    "        end,\n",
    "        1:length(data)\n",
    "    )\n",
    "    \n",
    "    sum(values)\n",
    "end\n",
    "\n",
    "@btime imager(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nervous-squad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  61.629 ms (25 allocations: 17.80 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10166.387038500514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime imager(CUDA.zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-actress",
   "metadata": {},
   "source": [
    "But we haven't yet taken advantage of the CUDA api. For this, we want to call the CUDA variant of `map`, which takes a CuArray as the second argument. Since we are just counting incrementally for `i`, we can pre-assemble this information using something like\n",
    "```julia\n",
    "reshape(collect(Float64, 1:width*height*3), (height, width, 3))\n",
    "```\n",
    "\n",
    "Implementing this new version, modifying `rinit` to be a `::Type`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daily-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imager (generic function with 2 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function imager(rinit::Type; height=720, width=1080)\n",
    "    data = reshape(\n",
    "        rinit(collect(Float64, 1:width*height*3)),\n",
    "        (height, width, 3)\n",
    "    )\n",
    "    \n",
    "    h_mid = height ÷ 2\n",
    "    w_mid = width ÷ 2\n",
    "        \n",
    "    values = map(\n",
    "        (i) -> begin \n",
    "            # find position\n",
    "            z = (i-1) ÷ (width * height)\n",
    "            y = (i-1 - z*width*height) ÷ width\n",
    "            x = i - ( z*width*height + y * width ) - w_mid\n",
    "            y += 1\n",
    "            z += 1\n",
    "            \n",
    "            β2 = atan(y - h_mid, x) # atan2\n",
    "            r = sqrt(x^2 + (y - h_mid)^2)\n",
    "            \n",
    "            β2\n",
    "        end,\n",
    "        data\n",
    "    )\n",
    "    \n",
    "    sum(values)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "surgical-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  125.598 ms (12 allocations: 53.39 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10166.387038500514"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime imager(Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bigger-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(atan(y::T, x::T) where T<:Union{Float32, Float64} in Base.Math at special/trig.jl:567, atan(x::Float64, y::Float64) in CUDA at /home/ovid/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:38), Base.StackTraces.StackFrame[atan at trig.jl:567, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n",
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(atan(x::T) where T<:Union{Float32, Float64} in Base.Math at special/trig.jl:503, atan(x::Float64) in CUDA at /home/ovid/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:32), Base.StackTraces.StackFrame[atan at trig.jl:503, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.421 ms (112 allocations: 17.80 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10166.387038500417"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime imager(CuArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-baking",
   "metadata": {},
   "source": [
    "That's looking more like it! However in doing this we have massively slowed down the CPU version over the initial implementation. But this is to be expected, and we can ammend the dispatch issues for CPU vs GPU later once we have squeezed performance.\n",
    "\n",
    "*NB*: there is a slight biasing in this implementation towards the GPU, since for the CPU we call\n",
    "```julia\n",
    "Array(collect(...))\n",
    "```\n",
    "This barely changes the speed of the CPU version (<10 ms), but does reduce allocations significantly. I implemented it as above for ease of interoperability, though really I should be using the multiple dispatch to achieve this.\n",
    "\n",
    "*Also NB*: we get GPU warnings about `atan` in `Base`. I'll investigate this later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-cursor",
   "metadata": {},
   "source": [
    "## Reimplementing\n",
    "Let's reimplement the rendering function with just this change. I'm also going to take the liberty to slightly adjust the interface for multiple dispatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opponent-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "renderdisk! (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function renderdisk!(\n",
    "    α::Float64,\n",
    "    β::Float64,\n",
    "    geodesics,\n",
    "    data # no type to support recompilation on CuArray\n",
    "    ;\n",
    "    height::Int=720,\n",
    "    width::Int=1080,\n",
    "    fov_index::Int=200\n",
    "    )\n",
    "    \n",
    "    \n",
    "    h_mid = height ÷ 2\n",
    "    w_mid = width ÷ 2\n",
    "    \n",
    "    n = size(geodesics)[1] ÷ 3\n",
    "        \n",
    "    values = map(\n",
    "        (i) -> begin \n",
    "            # find position\n",
    "            z = (i-1) ÷ (width * height)\n",
    "            y = (i-1 - z*width*height) ÷ width\n",
    "            x = i - ( z*width*height + y * width ) - w_mid\n",
    "            y += 1\n",
    "            z += 1\n",
    "            \n",
    "            β2 = atan(y - h_mid, x) # atan2\n",
    "            r = sqrt(x^2 + (y - h_mid)^2)\n",
    "            \n",
    "            # additional steps here\n",
    "            index = convert(Int, floor(1 + r / fov_index * n))\n",
    "            \n",
    "            # we no longer assign directly, but return new value\n",
    "            ret = 0.0\n",
    "            if index < n\n",
    "                # has to calculate intersection three times, but this will be optimized later\n",
    "                ret = truncator(intersection(geodesics[index:index+2, :], α, β + β2))\n",
    "            end\n",
    "            ret\n",
    "        end,\n",
    "        data\n",
    "    )\n",
    "    \n",
    "    sum(values)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-williams",
   "metadata": {},
   "source": [
    "Let's now benchmark this new implementation, noting that, for comparison purposes, we also need to time the array creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "general-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  697.943 ms (376129 allocations: 2.64 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "837741.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test(geodesics, rinit::Type; height=720, width=1080)\n",
    "    data = reshape(\n",
    "        rinit(collect(Float64, 1:width*height*3)),\n",
    "        (height, width, 3)\n",
    "    )\n",
    "    \n",
    "    # squash so geodesics can be copied in CUDA.map call\n",
    "    geodesics = vcat(geodesics...)\n",
    "    \n",
    "    renderdisk!(π/100, 0.0, geodesics, data; height=height, width=width)\n",
    "end\n",
    "\n",
    "@btime test($geodesics, Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expanded-links",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(atan(y::T, x::T) where T<:Union{Float32, Float64} in Base.Math at special/trig.jl:567, atan(x::Float64, y::Float64) in CUDA at /home/ovid/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:38), Base.StackTraces.StackFrame[atan at trig.jl:567, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n",
      "┌ Warning: calls to Base intrinsics might be GPU incompatible\n",
      "│   exception = (GPUCompiler.MethodSubstitutionWarning(atan(x::T) where T<:Union{Float32, Float64} in Base.Math at special/trig.jl:503, atan(x::Float64) in CUDA at /home/ovid/.julia/packages/CUDA/wTQsK/src/device/intrinsics/math.jl:32), Base.StackTraces.StackFrame[atan at trig.jl:503, broadcast_kernel at broadcast.jl:59])\n",
      "└ @ GPUCompiler /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/irgen.jl:68\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "GPU compilation of kernel broadcast_kernel(CUDA.CuKernelContext, CuDeviceArray{Float64,3,1}, Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}, Int64) failed\nKernelError: passing and using non-bitstype argument\n\nArgument 4 to your kernel function is of type Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}, which is not isbits:\n  .f is of type var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64} which is not isbits.\n    .geodesics is of type CuArray{Float64,2} which is not isbits.\n      .ctx is of type CuContext which is not isbits.\n\n",
     "output_type": "error",
     "traceback": [
      "GPU compilation of kernel broadcast_kernel(CUDA.CuKernelContext, CuDeviceArray{Float64,3,1}, Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}, Int64) failed\nKernelError: passing and using non-bitstype argument\n\nArgument 4 to your kernel function is of type Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}}, which is not isbits:\n  .f is of type var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64} which is not isbits.\n    .geodesics is of type CuArray{Float64,2} which is not isbits.\n      .ctx is of type CuContext which is not isbits.\n\n",
      "",
      "Stacktrace:",
      " [1] check_invocation(::GPUCompiler.CompilerJob, ::LLVM.Function) at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/validation.jl:68",
      " [2] macro expansion at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/driver.jl:238 [inlined]",
      " [3] macro expansion at /home/ovid/.julia/packages/TimerOutputs/ZmKD7/src/TimerOutput.jl:206 [inlined]",
      " [4] codegen(::Symbol, ::GPUCompiler.CompilerJob; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool) at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/driver.jl:237",
      " [5] compile(::Symbol, ::GPUCompiler.CompilerJob; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool) at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/driver.jl:39",
      " [6] compile at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/driver.jl:35 [inlined]",
      " [7] cufunction_compile(::GPUCompiler.FunctionSpec; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/ovid/.julia/packages/CUDA/wTQsK/src/compiler/execution.jl:302",
      " [8] cufunction_compile(::GPUCompiler.FunctionSpec) at /home/ovid/.julia/packages/CUDA/wTQsK/src/compiler/execution.jl:297",
      " [9] check_cache(::Dict{UInt64,Any}, ::Any, ::Any, ::GPUCompiler.FunctionSpec{GPUArrays.var\"#broadcast_kernel#12\",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,1},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}},Int64}}, ::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/cache.jl:40",
      " [10] broadcast_kernel at /home/ovid/.julia/packages/GPUArrays/WV76E/src/host/broadcast.jl:60 [inlined]",
      " [11] cached_compilation at /home/ovid/.julia/packages/GPUCompiler/uTpNx/src/cache.jl:65 [inlined]",
      " [12] cufunction(::GPUArrays.var\"#broadcast_kernel#12\", ::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,1},Base.Broadcast.Broadcasted{Nothing,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{Base.Broadcast.Extruded{CuDeviceArray{Float64,3,1},Tuple{Bool,Bool,Bool},Tuple{Int64,Int64,Int64}}}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /home/ovid/.julia/packages/CUDA/wTQsK/src/compiler/execution.jl:289",
      " [13] cufunction at /home/ovid/.julia/packages/CUDA/wTQsK/src/compiler/execution.jl:286 [inlined]",
      " [14] macro expansion at /home/ovid/.julia/packages/CUDA/wTQsK/src/compiler/execution.jl:100 [inlined]",
      " [15] #launch_heuristic#857 at /home/ovid/.julia/packages/CUDA/wTQsK/src/gpuarrays.jl:17 [inlined]",
      " [16] launch_heuristic at /home/ovid/.julia/packages/CUDA/wTQsK/src/gpuarrays.jl:17 [inlined]",
      " [17] copyto! at /home/ovid/.julia/packages/GPUArrays/WV76E/src/host/broadcast.jl:66 [inlined]",
      " [18] copyto! at ./broadcast.jl:886 [inlined]",
      " [19] copy at ./broadcast.jl:862 [inlined]",
      " [20] materialize(::Base.Broadcast.Broadcasted{CUDA.CuArrayStyle{3},Nothing,var\"#17#18\"{Int64,Int64,Int64,Float64,Float64,CuArray{Float64,2},Int64,Int64,Int64},Tuple{CuArray{Float64,3}}}) at ./broadcast.jl:837",
      " [21] map(::Function, ::CuArray{Float64,3}) at /home/ovid/.julia/packages/GPUArrays/WV76E/src/host/broadcast.jl:89",
      " [22] renderdisk!(::Float64, ::Float64, ::CuArray{Float64,2}, ::CuArray{Float64,3}; height::Int64, width::Int64, fov_index::Int64) at ./In[13]:18",
      " [23] test(::Array{CuArray{Float64,2},1}, ::Type{T} where T; height::Int64, width::Int64) at ./In[14]:10",
      " [24] test at ./In[14]:2 [inlined]",
      " [25] ##core#391(::Array{CuArray{Float64,2},1}) at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:371",
      " [26] ##sample#392(::BenchmarkTools.Parameters) at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:377",
      " [27] _run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#390\")}, ::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{4,Symbol},NamedTuple{(:samples, :evals, :gctrial, :gcsample),Tuple{Int64,Int64,Bool,Bool}}}) at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:405",
      " [28] (::Base.var\"#inner#2\"{Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}},typeof(BenchmarkTools._run),Tuple{BenchmarkTools.Benchmark{Symbol(\"##benchmark#390\")},BenchmarkTools.Parameters}})() at ./essentials.jl:713",
      " [29] #invokelatest#1 at ./essentials.jl:714 [inlined]",
      " [30] #run_result#37 at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:32 [inlined]",
      " [31] run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#390\")}, ::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}}) at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:94",
      " [32] #warmup#45 at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141 [inlined]",
      " [33] warmup(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#390\")}) at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:141",
      " [34] top-level scope at /home/ovid/.julia/packages/BenchmarkTools/eCEpo/src/execution.jl:481",
      " [35] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@btime test($gpugeo, CuArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-cattle",
   "metadata": {},
   "source": [
    "This is a bit problematic. I obviously don't want a unique copy of `gpugeo` per GPU thread, and would like to put these arrays in read-only memory, so they can be accessed as needed for computational purposes. The alternative would be to pre-assemble the data required for each pixel in-place, but that would conflate the memory needs massively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-league",
   "metadata": {},
   "source": [
    "## Texture Memory\n",
    "I then stumbled accross an interesting section of the docs on [Texture Memory](https://juliagpu.github.io/CUDA.jl/stable/lib/driver/#CUDA.CuTexture-Tuple{Any}), which is interpolated read-only memory, nested around a CuArray, which I may be able to distribute over the threads:\n",
    "> Construct a N-dimensional texture object with elements of type T as stored in parent.\n",
    ">\n",
    ">Several keyword arguments alter the behavior of texture objects:\n",
    ">\n",
    ">    - address_mode (wrap, clamp, mirror): how out-of-bounds values are accessed. Can be specified as a value for all dimensions, or as a tuple of N entries.\n",
    ">\n",
    ">    - interpolation (nearest neighbour, linear, bilinear): how non-integral indices are fetched. Nearest-neighbour fetches a single value, others interpolate between multiple.\n",
    ">\n",
    ">    - normalized_coordinates (true, false): whether indices are expected to fall in the normalized [0:1) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unknown-proof",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: CUDA does not support texture arrays for element type Float64.",
     "output_type": "error",
     "traceback": [
      "ArgumentError: CUDA does not support texture arrays for element type Float64.",
      "",
      "Stacktrace:",
      " [1] convert(::Type{CUDA.CUarray_format_enum}, ::Type{T} where T) at /home/ovid/.julia/packages/CUDA/wTQsK/lib/cudadrv/memory.jl:720",
      " [2] alloc(::Type{CUDA.Mem.ArrayBuffer{Float64,N} where N}, ::Tuple{Int64,Int64}) at /home/ovid/.julia/packages/CUDA/wTQsK/lib/cudadrv/memory.jl:290",
      " [3] CuTextureArray{Float64,2}(::UndefInitializer, ::Tuple{Int64,Int64}) at /home/ovid/.julia/packages/CUDA/wTQsK/src/texture.jl:40",
      " [4] CuTextureArray at /home/ovid/.julia/packages/CUDA/wTQsK/src/texture.jl:93 [inlined]",
      " [5] CuTextureArray(::CuArray{Float64,2}) at /home/ovid/.julia/packages/CUDA/wTQsK/src/texture.jl:101",
      " [6] top-level scope at In[16]:1",
      " [7] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "CuTextureArray(gpugeo[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-thirty",
   "metadata": {},
   "source": [
    "But annoyingly we can't get Float64 support. We could cast it to Float32, which it does support, but I am increasingly unsure if these structures are what I want, amplified by the fact that the API is still experimental."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-merchandise",
   "metadata": {},
   "source": [
    "## Memmory Management\n",
    "Examining the docs a little further, under their section on [Memmory Management](https://juliagpu.github.io/CUDA.jl/stable/lib/driver/#Memory-Management) are a few ways we can allocate and free memory on the GPU.\n",
    "\n",
    "From the docs, there are two functions which I think might solve my problem:\n",
    "\n",
    "> ```julia\n",
    "> Mem.alloc(DeviceBuffer, bytesize::Integer)\n",
    "> ```\n",
    ">\n",
    "> Allocate bytesize bytes of memory on the device. This memory is only accessible on the GPU, and requires explicit calls to `unsafe_copyto!`, which wraps `cuMemcpy`, for access on the CPU.\n",
    "\n",
    "and possibly\n",
    "\n",
    "> ```julia\n",
    "> Mem.register(HostBuffer, ptr::Ptr, bytesize::Integer, [flags])\n",
    "> ```\n",
    "> \n",
    "> Page-lock the host memory pointed to by `ptr`. Subsequent transfers to and from devices will be faster, and can be executed asynchronously. If the `HOSTREGISTER_DEVICEMAP` flag is specified, the buffer will also be accessible directly from the GPU. These accesses are direct, and go through the PCI bus. If the `HOSTREGISTER_PORTABLE` flag is specified, any CUDA context can access the memory.\n",
    "\n",
    "The second method would prevent having to upload, but would bottle neck at during reads. That being said, there are generally more pixels where no read is required, but I still am opting in favour of `alloc`.\n",
    "\n",
    "I'm thinking it's going to give me the speed, and I can use it without too much restriction, since I'm allocating a very small amount of memory. I think. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "undefined-cattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4236902400"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.total_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "automotive-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeof(Float64) * sum(length, geodesics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-oklahoma",
   "metadata": {},
   "source": [
    "Yeah, that's shouldn't be a problem, with plently of space to scale vertically!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-strap",
   "metadata": {},
   "source": [
    "### A single geodesic\n",
    "Let's see if we can allocate a single curve, and access it in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "twelve-newark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceBuffer(7.031 KiB at 0x0000000501d58c00)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve = geodesics[1]\n",
    "curve_p = CUDA.Mem.alloc(\n",
    "    CUDA.Mem.DeviceBuffer,\n",
    "    sizeof(Float64) * length(curve)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-motorcycle",
   "metadata": {},
   "source": [
    "Going to make sure I understood the API for freeing also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "actual-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.Mem.free(curve_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-liquid",
   "metadata": {},
   "source": [
    "Yep, that works fine. \n",
    "\n",
    "Whilst trying to find more info on the `DeviceBuffer` API, I stumbled on a [few macros](https://juliagpu.github.io/CUDA.jl/stable/api/kernel/#Memory-types) which may also do what I want:\n",
    "\n",
    "> ```julia\n",
    "> @cuStaticSharedMem(T::Type, dims) -> CuDeviceArray{T,AS.Shared}\n",
    "> ```\n",
    "> \n",
    "> Get an array of type `T` and dimensions `dims` (either an integer length or tuple shape) pointing to a statically-allocated piece of shared memory. The type should be statically inferable and the dimensions should be constant, or an error will be thrown and the generator function will be called dynamically.\n",
    "\n",
    "Which, if I understand correctly should allow me to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "architectural-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×300 device array at Core.LLVMPtr{Float64,3}(0x00007ff2000f0120)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve_mem = @cuStaticSharedMem Float64 (3, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-projection",
   "metadata": {},
   "source": [
    "Nice, it returns a proper `LLVMPtr`! Now we're in familiar territory. \n",
    "\n",
    "*NB*: I'm not entirely certain where this memory is located however... I get the suspicion this has been allocated on the host and shared with the device, but I am unsure how to check. \n",
    "\n",
    "Thankfully I'm not the first person to ponder this, and found [this NVIDIA developer page](https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/) containing more information on what \"Shared Memory\" means in the context of GPUs.\n",
    "\n",
    "It is memory *allocated* on the GPU device, *shared* between threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "immediate-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isbits(curve_mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-bailey",
   "metadata": {},
   "source": [
    "Perfect! So let's try this proof of concept with a conceptual function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "legal-arrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shared_test (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function shared_test(curve)\n",
    "    \n",
    "    curve_mem = @cuStaticSharedMem Float64 (3, 300)\n",
    "    curve_mem[:] = curve[:]\n",
    "    \n",
    "    data = CuArray(collect(Float32, 1:10000)) # something decently sized\n",
    "    map(\n",
    "        i -> begin\n",
    "            index = convert(Int, i % (3*300) + 1)\n",
    "            curve_mem[index]\n",
    "        end,\n",
    "        data\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "statewide-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared_test(curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-berry",
   "metadata": {},
   "source": [
    "This doesn't seem to work. I am encountering an `ERROR 700 ILLEGAL MEMORY ACCESS` which isn't boding well, and likewise I seem to be reading that shared memory is [significantly smaller](https://stackoverflow.com/a/20909276) than I'd at first hoped.\n",
    "\n",
    "But this has given me an idea... maybe I can pass pointers directly to the CuArrays?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-norwegian",
   "metadata": {},
   "source": [
    "### Pointers\n",
    "Provided the pointer `isbits`, then we should be able to pass the tuple of pointers to each thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "balanced-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×300 CuArray{Float64,2}:\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curve = gpugeo[1]\n",
    "p = Ref(curve)\n",
    "p[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sublime-dance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isbits(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "industrial-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuPtr{Float64}(0x0000000504660000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pointer(curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-murder",
   "metadata": {},
   "source": [
    "Which is probably not a good direction to be going in.\n",
    "\n",
    "I think I'm going to read more about how the GPU works, as I am now well and truly outside of the realm of `CuArray`s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-nightlife",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
