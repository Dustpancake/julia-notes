{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "headed-massage",
   "metadata": {},
   "source": [
    "# GPU Memory and CUDA.jl\n",
    "This notebook contains notes on the GPU memory layout, processing, and some of the lower-level access to the CUDA API which interfaces with those aspects, as well as the specific CUDA.jl bindings.\n",
    "\n",
    "I watched a series of videos last night, which explain how CUDA functions\n",
    "- [CUDA Tutorials](https://www.youtube.com/watch?v=m0nhePeHwFs&list=PLKK11Ligqititws0ZOoGk3SW-TZCar4dK) by Creel\n",
    "- [Intro to Cuda](https://www.youtube.com/watch?v=cRY5utouJzQ) by Josh Holloway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-adjustment",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In short, the GPU memory and architecture looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-pioneer",
   "metadata": {},
   "source": [
    "![](./gpumem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-safety",
   "metadata": {},
   "source": [
    "### Computation\n",
    "The principle units of GPU processing are *Threads*, which in CUDA are arranged into *Blocks*. GPUs use this block-based processing design so that the same code can run irrespective of the GPU model itself, with more powerful GPUs churning through more blocks at a time.\n",
    "\n",
    "The GPU has a number of *Streaming Multiprocessors* (SM), each consisting of a number of *Streaming Processors* (SP), which are scalar lanes, running a single thread at a time. A SM schedules instructions to the SP as it executes a block, through the *warp scheduler*.\n",
    "\n",
    "A block is exectuted in *warps*, where a single *warp* is usually defined as the execution of 32 simultaneous threads (related to memory access transaction specifics, see [this SO answer](https://stackoverflow.com/a/11821971)).\n",
    "\n",
    "A single block can hold up to 1024 threads, and there is no practical limit on the number of blocks you can define. \n",
    "\n",
    "An overall scheduler on the GPU will distribute blocks to the SMs, which in turn will execute a number of warps per clock cycle until all of the blocks have been completed.\n",
    "\n",
    "In CUDA, when we launch a processing kernel (a routine/algorithm/function) on the GPU, we can specifiy the block layout, and within those blocks, the number of threads.\n",
    "\n",
    "The block layout is known as a *grid*.\n",
    "\n",
    "There's elements of tradeoffs between number of threads and the shared memory in a block, which is why you may want to limit these things, but I haven't investigated consequences of not just maxing the number of threads per block beyond that. Something to learn in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-nature",
   "metadata": {},
   "source": [
    "### Memory\n",
    "Now this is the bit particularly relevant to my initial investigation yesterday.\n",
    "\n",
    "Each block has shared memory, which is stored on-chip of the SM. This memory is typically rather small (10s of kilobytes), and is used for intercommunication between threads. The RW operations are consequently very fast by proximity. Shared memory is accessed through an L1 cache, so write operations to shared memory must be synchronised.\n",
    "\n",
    "Each thread has register memory (unlike CPUs, there are many thousand GPU registers) for storing immediate data, and any spillover from register memory is stored in the thread's local memory. Now despite the name, the local memory is off-chip, stored in the GPUs equivalent of DRAM, and so RW operations are slow. The local memory is owned and exclussively accessible by the running thread, as, of course, as the registers.\n",
    "\n",
    "Then there is the global memory, which is host not only to each thread's local memory, but itself represents memory that each thread can read and write to, albeit slow by distance, and not write-threadsafe.\n",
    "\n",
    "The global memory also houses the constant memory (sections of read-only written by the CPU and locked when a kernel launches), and the texture memory, which is special interpolated read-only memory.\n",
    "\n",
    "On modern GPUs, the global memory is accessed through an L2 cache.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-fraud",
   "metadata": {},
   "source": [
    "## Learning about a device\n",
    "The CUDA library provides different tools for obtaining information on GPU devices, such as the command line `nvidia-smi` for a whole range of information. However CUDA.jl provides bindings for much of what we would need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "later-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "welsh-transportation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(0): GeForce GTX 980"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = collect(CUDA.devices())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-forest",
   "metadata": {},
   "source": [
    "The [compute capability](https://forums.developer.nvidia.com/t/compute-capability/110091):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "binary-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"5.2.0\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.capability(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-taiwan",
   "metadata": {},
   "source": [
    "Numbers of threas per warp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "other-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.warpsize(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-royal",
   "metadata": {},
   "source": [
    "Number of threads per block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "federal-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-assault",
   "metadata": {},
   "source": [
    "The amount of shared memory per block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alleged-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-columbia",
   "metadata": {},
   "source": [
    "which is about 46 KB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-festival",
   "metadata": {},
   "source": [
    "Total constant memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vulnerable-barrier",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-bowling",
   "metadata": {},
   "source": [
    "Maximum number of registers per block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dangerous-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fluid-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-graduation",
   "metadata": {},
   "source": [
    "Multiprocessor count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "modified-chosen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-alaska",
   "metadata": {},
   "source": [
    "Something I was toying with, which is an option again now that I understand the memory layout better, was storing my calculated geodesics in texture memory so I can float index them. Texture memory can be stored in 1, 2 or 3 dimensions -- and we can see the maximum amount of memory in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "laden-accountability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.attribute(dev, CUDA.CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-syndicate",
   "metadata": {},
   "source": [
    "## Re-evaluating my approach\n",
    "Yesterday I focused on trying to use the `map` command defined for `CuArray`, which invokes its own kernel function. As such, I don't think I have fine tuned control over the memory (although I could be wrong), and instead may have to write my own kernel to achieve this level of geodesic tracing.\n",
    "\n",
    "I want to try a few more things with `CuArray`s first before I give up and learn about writing Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-desperate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
