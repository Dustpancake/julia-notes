{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72132294",
   "metadata": {},
   "source": [
    "# Writing practical CUDA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6f0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA, BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ac68f",
   "metadata": {},
   "source": [
    "## Thread unique identifier\n",
    "\n",
    "We calculate the thread unique identifier using a simple formula\n",
    "\n",
    "$$\n",
    "    \\text{id} = x_{\\text{thread}} + N \\left( x_{\\text{block}}  - 1 \\right)\n",
    "$$\n",
    "\n",
    "where $N$ is the number of threads per block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b2a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kernel(a)\n",
    "    i = threadIdx().x + blockDim().x * (blockIdx().x - 1)\n",
    "    \n",
    "    a[i] = i\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d73dee",
   "metadata": {},
   "source": [
    "Launching this kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee839da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element CuArray{Float32, 1}:\n",
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       " 6.0\n",
       " 7.0\n",
       " 8.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.zeros(8)\n",
    "\n",
    "@cuda threads=4 blocks=2 kernel(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fcfeb",
   "metadata": {},
   "source": [
    "## Kernel occupancy\n",
    "\n",
    "Finding the right balance between threads and blocks that fully utilize the GPU effectively can be tricky. Fortunately, we can utilize tools to assist finding the optimal launch configuration by compiling our kernel and inspecting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7769c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kernel (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function kernel(c, a, b)\n",
    "    i = threadIdx().x + blockDim().x * (blockIdx().x - 1)\n",
    "    \n",
    "    c[i] = a[i] + 2 * b[i]\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c642225",
   "metadata": {},
   "source": [
    "To analyse our launch, we require some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f782cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray(1:4096)\n",
    "b = reverse(copy(a))\n",
    "c = similar(a) \n",
    "; # no ouput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d33c8",
   "metadata": {},
   "source": [
    "Attempting a poor configuration also results in poorer performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145f2b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 4 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m7.535 μs\u001b[22m\u001b[39m … \u001b[35m 1.007 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 99.01%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m7.790 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m7.988 μs\u001b[22m\u001b[39m ± \u001b[32m10.003 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.25% ±  0.99%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m█\u001b[34m▃\u001b[39m\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[32m▆\u001b[39m\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
       "  7.53 μs\u001b[90m        Histogram: frequency by time\u001b[39m        11.2 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.45 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m38\u001b[39m."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads = 32\n",
    "blocks = cld(length(a), 32)  # ceil division\n",
    "\n",
    "@benchmark CUDA.@sync @cuda threads=threads blocks=blocks kernel($c, $a, $b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f017b0c",
   "metadata": {},
   "source": [
    "Now we compile with `launch=false` and analyse the optimal launch configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e5aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf = (blocks = 32, threads = 1024)\n",
      "calc = (blocks = 4, threads = 1024)"
     ]
    }
   ],
   "source": [
    "kern = @cuda launch=false kernel(c, a, b)\n",
    "\n",
    "conf = CUDA.launch_configuration(kern.fun)\n",
    "@show conf\n",
    "\n",
    "threads = min(length(a), conf.threads)\n",
    "blocks  = cld(length(a), threads)\n",
    "\n",
    "print(\"calc = (blocks = $blocks, threads = $threads)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d989207",
   "metadata": {},
   "source": [
    "We can then launch our compiled kernel through a function invocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4138e899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.996 μs\u001b[22m\u001b[39m … \u001b[35m552.159 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 99.50%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.122 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.273 μs\u001b[22m\u001b[39m ± \u001b[32m  7.781 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m4.83% ±  1.41%\n",
       "\n",
       "  \u001b[39m \u001b[39m▁\u001b[39m▆\u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[32m▄\u001b[39m\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
       "  2 μs\u001b[90m            Histogram: frequency by time\u001b[39m        3.77 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.03 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m23\u001b[39m."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark kern($c, $a, $b; threads, blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad100bd2",
   "metadata": {},
   "source": [
    "In general a good launch configuration will perform well on any CUDA GPU device, though the optimal may very well be device dependent. As always, profiling and benchmarking is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64721cd8",
   "metadata": {},
   "source": [
    "## A `reduce` implementation\n",
    "We can demonstrate some GPU idioms by examining how we might write a reduce function on the GPU.\n",
    "\n",
    "The GPU is best utilized by launching independed (trivially parallelizeable) threads. There are a few ways we can keep this practice, and still implement `reduce` effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff5cda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element CuArray{Float32, 1}:\n",
       " 0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(1024, 1024)\n",
    "b = CuArray{Float32, 1}([0]) # result store, samne type as a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62494e",
   "metadata": {},
   "source": [
    "For comparison, we benchmark the CPU with 1024x1024 elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b4d77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m73.902 μs\u001b[22m\u001b[39m … \u001b[35m246.050 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m74.465 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m74.902 μs\u001b[22m\u001b[39m ± \u001b[32m  3.705 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▆\u001b[39m█\u001b[34m█\u001b[39m\u001b[32m▂\u001b[39m\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[32m█\u001b[39m\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  73.9 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      91.4 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_a = Array(a)\n",
    "@benchmark sum($cpu_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146ece4",
   "metadata": {},
   "source": [
    "### Avoiding write conflicts with `CUDA.@atomic`\n",
    "\n",
    "A basic implementation leveraging atomics to avoid write conflicts may look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deaf574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1734 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.743 ms\u001b[22m\u001b[39m … \u001b[35m  5.306 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 44.34%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.984 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.882 ms\u001b[22m\u001b[39m ± \u001b[32m134.470 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.12% ±  2.25%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▄\u001b[39m▆\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  2.74 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m         3 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m32.56 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2070\u001b[39m."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_kernel(op, a, b)\n",
    "    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x\n",
    "    \n",
    "    @atomic b[] = op(b[], a[i])\n",
    "    \n",
    "    return\n",
    "end\n",
    "\n",
    "@benchmark CUDA.@sync @cuda threads=1024 blocks=1024 reduce_kernel(+, $a, $b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecdfaad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element CuArray{Float32, 1}:\n",
       " 0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CUDA.rand(1024, 1024)\n",
    "b = CuArray{Float32, 1}([0]) # result store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f06490",
   "metadata": {},
   "source": [
    "Note that these atomics result is serialization of access, and thus slow the kernel dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722891d",
   "metadata": {},
   "source": [
    "### Thread reduction\n",
    "\n",
    "The idea is to implement a reduction along the lines of (`length(a)=16`)\n",
    "```\n",
    "itt 1:\n",
    "thread 1: a[1]  + a[2]  = 1  + 2   = 3\n",
    "thread 2: a[3]  + a[4]  = 3  + 4   = 7\n",
    "thread 3: a[5]  + a[6]  = 5  + 6   = 11\n",
    "thread 4: a[7]  + a[8]  = 7  + 8   = 15\n",
    "thread 5: a[9]  + a[10] = 9  + 10  = 19\n",
    "thread 6: a[11] + a[12] = 11 + 12  = 23\n",
    "thread 7: a[13] + a[14] = 13 + 14  = 27\n",
    "thread 8: a[15] + a[16] = 15 + 16  = 31\n",
    "\n",
    "itt 2:\n",
    "thread 1: a[1]  + a[3]  = 3  + 7   = 10\n",
    "thread 2: a[5]  + a[7]  = 11 + 15  = 26\n",
    "thread 3: a[9]  + a[11] = 19 + 23  = 42\n",
    "thread 4: a[13] + a[15] = 27 + 31  = 58\n",
    "\n",
    "itt 3:\n",
    "thread 1: a[1]  + a[5]  = 10 + 26  = 36\n",
    "thread 2: a[9]  + a[13] = 42 + 58  = 100\n",
    "\n",
    "itt 4:\n",
    "thread 1: a[1]  + a[9]  = 36 + 100 = 136\n",
    "```\n",
    "in a single block. This does limit our kernel to arrays of length 2 x 1024 = 2048, but provides the ground work for how we scale the pattern over many blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05104c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reduce_thread_kernel (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_thread_kernel(op, a, b)\n",
    "    elements = blockDim().x * 2\n",
    "    thread = threadIdx().x\n",
    "    \n",
    "    d = 1\n",
    "    while d < elements\n",
    "        \n",
    "        sync_threads()\n",
    "        i = 2 * d * (thread - 1) + 1\n",
    "        \n",
    "        @inbounds if i ≤ elements && i + d ≤ length(a)\n",
    "            a[i] = op(a[i], a[i+d])\n",
    "        end\n",
    "        d *= 2\n",
    "    end\n",
    "    \n",
    "    if thread == 1\n",
    "        b[] = a[1]\n",
    "    end\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711892d4",
   "metadata": {},
   "source": [
    "Trying out the function on a small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b1d18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = CuArray(1:1024)\n",
    "b1 = CuArray([0])\n",
    "\n",
    "# limit threads to half of data\n",
    "@cuda threads=cld(length(a1), 2) reduce_thread_kernel(+, a1, b1)\n",
    "\n",
    "CUDA.@allowscalar b1[1] == sum(1:1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e969f8",
   "metadata": {},
   "source": [
    "### Single block reduction\n",
    "\n",
    "We can generalise the above implementation for arbitrary array size by first reducing the array above the block size, and then running the algorithm as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442b82bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reduce_block_kernel (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_block_kernel(op, a, b)\n",
    "    elements = blockDim().x * 2 # as each thread consumes 2 elements\n",
    "    thread = threadIdx().x\n",
    "    \n",
    "    i = thread + elements\n",
    "    while i ≤ length(a)\n",
    "        \n",
    "        a[thread] = op(a[thread], a[i])\n",
    "        i += elements\n",
    "        \n",
    "    end\n",
    "    \n",
    "    d = 1\n",
    "    while d < elements\n",
    "        sync_threads()\n",
    "        i = 2 * d * (thread - 1) + 1\n",
    "        \n",
    "        @inbounds if i ≤ elements && i + d ≤ length(a)\n",
    "            a[i] = op(a[i], a[i+d])\n",
    "        end\n",
    "        d *= 2\n",
    "        \n",
    "    end\n",
    "    \n",
    "    if thread == 1\n",
    "        b[] = a[1]\n",
    "    end\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009cf8f",
   "metadata": {},
   "source": [
    "This effectively reduces the size of the array, over the first `while` loop, until the length of the array is equal to the number of threads. We can now benchmark this function with the original test data, however limiting the GPU to a processing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6aa97d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m235.713 μs\u001b[22m\u001b[39m … \u001b[35m 2.278 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 91.75%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m244.456 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m275.479 μs\u001b[22m\u001b[39m ± \u001b[32m68.080 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.15% ±  1.32%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▂\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▇\u001b[39m▄\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▂\n",
       "  236 μs\u001b[90m          Histogram: frequency by time\u001b[39m          409 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m4.23 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m257\u001b[39m."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync @cuda threads=1024 reduce_block_kernel(+, $a, $b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c93d9e",
   "metadata": {},
   "source": [
    "### Grid reduction with atomics\n",
    "\n",
    "To fully utilize the GPU, we want to run many blocks so that the GPU can switch between them without latency. To perform a multi-block (grid) reduction we have to take into account that each block is independent, and may not neccessarily be running at the same time as another block. Consequently, our hope to synchronise threads doesn't extend beyond a single block.\n",
    "\n",
    "Instead, we can use atomic operations to write each threads result to the output array before the block switches.\n",
    "\n",
    "Consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc3b9baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reduce_gric_atomic_kernel (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_gric_atomic_kernel(op, a, b)\n",
    "    \n",
    "    elements = blockDim().x * 2     # number of elements each block will consume\n",
    "    thread = threadIdx().x \n",
    "    block = blockIdx().x\n",
    "    \n",
    "    offset = (block - 1) * elements\n",
    "    \n",
    "    # parallel block reduction\n",
    "    d = 1\n",
    "    while d < elements\n",
    "        sync_threads()\n",
    "        \n",
    "        i = 2 * d * (thread - 1) + 1\n",
    "        @inbounds if i ≤ elements && offset + i + d ≤ length(a)\n",
    "            a[offset + i] = op(a[offset + i], a[offset + i + d])\n",
    "        end\n",
    "        \n",
    "        d *= 2\n",
    "    end\n",
    "    \n",
    "    # atomic reduction of this blocks value\n",
    "    if thread == 1\n",
    "        @atomic b[] = op(b[], a[offset + 1])\n",
    "    end\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75da12",
   "metadata": {},
   "source": [
    "Benchmarking this kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5628dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m150.457 μs\u001b[22m\u001b[39m … \u001b[35m 2.231 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 99.18%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m153.051 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m153.348 μs\u001b[22m\u001b[39m ± \u001b[32m20.818 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.14% ±  0.99%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[34m▇\u001b[39m\u001b[39m█\u001b[39m▅\u001b[32m▆\u001b[39m\u001b[39m▄\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▅\n",
       "  150 μs\u001b[90m          Histogram: frequency by time\u001b[39m          156 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m992 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m48\u001b[39m."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync @cuda threads=1024 blocks=512 reduce_gric_atomic_kernel(+, $a, $b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4841b74",
   "metadata": {},
   "source": [
    "Although faster, we are still relying on serial operations with the use of atomic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf69d63",
   "metadata": {},
   "source": [
    "### Shared memory\n",
    "\n",
    "Each block has its own shared memory between threads, which is stored on chip of the streaming multiprocessor. Although this memory is rather small, we can use it for communication between threads, and caching loads.\n",
    "\n",
    "We utilise both of these ideas here:\n",
    "\n",
    "A given thread writes its memory from `a` into a shared buffer, as well as the element it will be reducing with, along the lines of (ignoring the offset):\n",
    "```julia\n",
    "shared[thread] = a[thread]\n",
    "shared[thread + blockDim().x] = a[thread + blockDim.x()]\n",
    "```\n",
    "For a single block (`blockdim().x == 1`), these values are adjacent.\n",
    "\n",
    "The shared buffer thus holds two values per thread, and since we are running at most 1024 threads, the size of the buffer is fixed to 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e95720f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reduce_grid_atomic_shared_kernel (generic function with 2 methods)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reduce_grid_atomic_shared_kernel(op, a::AbstractArray{T}, b) where {T}\n",
    "    \n",
    "    elements = blockDim().x * 2\n",
    "    thread = threadIdx().x\n",
    "    block = blockIdx().x\n",
    "    \n",
    "    offset = (block-1) * elements\n",
    "\n",
    "    # copy into shared memory buffer\n",
    "    shared = @cuStaticSharedMem(T, (2048,))\n",
    "    @inbounds shared[thread] = a[offset+thread]\n",
    "    @inbounds shared[thread+blockDim().x] = a[offset+thread+blockDim().x]\n",
    "\n",
    "    # parallel reduction\n",
    "    d = 1\n",
    "    while d < elements\n",
    "        sync_threads()\n",
    "        \n",
    "        i = 2 * d * (thread-1) + 1\n",
    "        \n",
    "        @inbounds if i ≤ elements && offset + i + d ≤ length(a)\n",
    "            shared[i] = op(shared[i], shared[i + d])\n",
    "        end\n",
    "        \n",
    "        d *= 2\n",
    "    end\n",
    "    \n",
    "    # atomic end-of-block reduction\n",
    "    if thread == 1\n",
    "        @atomic b[] = op(b[], shared[1])\n",
    "    end\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c434d6",
   "metadata": {},
   "source": [
    "Benchmarking this also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8574105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m137.328 μs\u001b[22m\u001b[39m … \u001b[35m 2.558 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 95.25%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m139.799 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m139.935 μs\u001b[22m\u001b[39m ± \u001b[32m24.383 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.17% ±  0.95%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m▇\u001b[34m▇\u001b[39m\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▄\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▄\n",
       "  137 μs\u001b[90m          Histogram: frequency by time\u001b[39m          142 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m2.77 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m163\u001b[39m."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync @cuda threads=1024 blocks=512 reduce_grid_atomic_shared_kernel(+, $a, $b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57d5c8",
   "metadata": {},
   "source": [
    "Which gives us a small performance improvement. \n",
    "\n",
    "If we compare our efforts to the `sum` implementation in CUDA.jl, we see there is still a little effort to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "307bec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m 96.457 μs\u001b[22m\u001b[39m … \u001b[35m 21.465 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 40.07%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m100.062 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m118.998 μs\u001b[22m\u001b[39m ± \u001b[32m216.389 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.72% ±  0.40%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▂\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▇\u001b[39m▄\u001b[39m \u001b[39m▂\n",
       "  96.5 μs\u001b[90m          Histogram: frequency by time\u001b[39m          173 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m4.84 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m161\u001b[39m."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CUDA.@sync sum($a)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
